---
templateKey: blog-post
title: Fine-tuning과 LoRA 나만의 AI 모델을 만드는 방법
date: 2025-11-05T00:00:00.000Z
category: ai
description:
  Fine-tuning과 LoRA의 개념과 작동 원리를 설명합니다. Full Fine-tuning vs LoRA 비교, 실무 적용 방법, 비용과 성능 분석까지 알아봅니다.
tags:
  - Fine-tuning
  - 파인튜닝
  - LoRA
  - Low-Rank Adaptation
  - 모델 학습
  - AI
  - LLM
  - 도메인 특화
---

![Fine-tuning과 LoRA 나만의 AI 모델을 만드는 방법](/assets/ai.png "Fine-tuning과 LoRA 나만의 AI 모델을 만드는 방법")

채팅GPT는 일반적인 지식은 풍부하지만, 특정 회사의 정책이나 전문 분야 지식은 부족하다. 이런 한계를 극복하는 방법 중 하나가 Fine-tuning이다. 하지만 전체 모델을 재학습하는 것은 비용이 크다. LoRA는 적은 파라미터만 조정해 비용을 대폭 줄이는 혁신적 기법이다. 이 글은 Fine-tuning과 LoRA의 원리를 설명하고, 실무에서 어떻게 활용할 수 있는지 보여준다.

## Fine-tuning이란 무엇인가?

Fine-tuning은 이미 학습된 모델을 특정 작업이나 도메인에 맞게 추가로 학습시키는 과정이다. 큰 모델을 처음부터 학습하는 것보다 훨씬 효율적이다.

### 사전 학습 vs Fine-tuning

**사전 학습 (Pre-training)**
- 목적: 일반적인 언어 능력 학습
- 데이터: 인터넷의 모든 텍스트 (수백 GB)
- 비용: 수십만 달러, 수개월 소요
- 결과: GPT-3, GPT-4 같은 범용 모델

**Fine-tuning**
- 목적: 특정 작업에 특화
- 데이터: 특정 도메인 데이터 (수 MB ~ 수 GB)
- 비용: 수백~수천 달러, 수일~수주 소요
- 결과: 법률, 의학, 금융 등 특화 모델

### Fine-tuning의 필요성

일반 LLM은 다음 한계가 있다:

1. **도메인 전문 지식 부족**
   - 법률 용어, 의학 용어를 정확히 이해하지 못함
   - 업계 특수 용어 처리 어려움

2. **회사 고유 정보 부재**
   - 회사 정책, 내부 문서 정보 없음
   - RAG로는 해결되지 않는 패턴 학습 필요

3. **출력 형식 제어 어려움**
   - 특정 형식으로 답변 생성이 어려움
   - 일관된 스타일 유지 어려움

Fine-tuning은 이런 문제를 해결한다.

## Full Fine-tuning의 작동 원리

Full Fine-tuning은 모델의 모든 파라미터를 업데이트하는 방식이다.

### 과정

1. **사전 학습 모델 로드**
   - GPT-3, GPT-4 같은 큰 모델 가져오기

2. **특정 데이터 준비**
   - 질문-답변 쌍, 문서, 대화 데이터 등

3. **전체 파라미터 학습**
   - 모델의 모든 가중치를 조금씩 조정
   - 예: 1750억 개 파라미터 모두 업데이트

4. **새 모델 저장**
   - 학습된 모델을 별도로 저장

### Full Fine-tuning의 장단점

**장점**
- 높은 성능 향상
- 모델 전체를 최적화
- 복잡한 패턴 학습 가능

**단점**
- 비용이 매우 높음 (수천~수만 달러)
- 시간이 오래 걸림 (수일~수주)
- 메모리 요구량이 큼 (GPU 여러 개 필요)
- 원본 모델과 별도로 관리해야 함

### 비용 예시

GPT-3.5 Fine-tuning 기준:
- 모델 크기: 1750억 파라미터
- 학습 데이터: 10,000개 예시
- 예상 비용: $3,000-10,000
- 학습 시간: 3-7일
- GPU 필요: A100 8개 이상

## LoRA: 혁신적인 효율적 Fine-tuning

LoRA (Low-Rank Adaptation)는 모델의 일부만 조정해 비용을 대폭 줄이는 기법이다.

### LoRA의 핵심 아이디어

전체 모델을 재학습하는 대신, 작은 행렬을 추가해 학습한다.

**기존 방식 (Full Fine-tuning)**
```
전체 모델 (1750억 파라미터) → 모두 업데이트
```

**LoRA 방식**
```
전체 모델 (1750억 파라미터) → 그대로 유지
+ 작은 행렬 (100만 파라미터) → 이것만 학습
```

### LoRA의 작동 원리

LoRA는 행렬 분해를 활용한다.

**원래 가중치 행렬**
- 크기: 4096 × 4096 (약 1,600만 파라미터)

**LoRA 접근**
- 원래 가중치: W (고정)
- LoRA 행렬: A × B (학습)
  - A: 4096 × 8 (32,768 파라미터)
  - B: 8 × 4096 (32,768 파라미터)
  - 총합: 65,536 파라미터 (원래의 0.4%)

**최종 출력**
```
출력 = W × 입력 + (B × A) × 입력
```

작은 행렬만 학습하면 되므로 비용이 크게 줄어든다.

### LoRA의 장단점

**장점**
- 비용이 매우 낮음 (Full Fine-tuning의 1/100)
- 학습 속도가 빠름 (수시간~1일)
- 메모리 요구량이 적음 (GPU 1-2개로 가능)
- 여러 작업별 LoRA를 저장해 재사용 가능
- 원본 모델은 그대로 유지

**단점**
- 성능이 Full Fine-tuning보다 약간 낮을 수 있음
- 매우 복잡한 패턴 학습에는 한계

### LoRA 비용 예시

GPT-3.5 LoRA Fine-tuning 기준:
- 모델 크기: 1750억 파라미터 (원본 유지)
- LoRA 파라미터: 100만~1000만 개
- 학습 데이터: 10,000개 예시
- 예상 비용: $30-100
- 학습 시간: 2-6시간
- GPU 필요: A100 1개

## Full Fine-tuning vs LoRA 비교

| 구분 | Full Fine-tuning | LoRA |
|------|------------------|------|
| **파라미터 업데이트** | 전체 (1750억 개) | 일부 (100만~1000만 개) |
| **비용** | $3,000-10,000 | $30-100 |
| **학습 시간** | 3-7일 | 2-6시간 |
| **GPU 필요량** | A100 8개 이상 | A100 1-2개 |
| **성능** | ⭐⭐⭐⭐⭐ | ⭐⭐⭐⭐ |
| **모델 크기** | 원본과 동일 | 원본 + 작은 파일 (MB 단위) |
| **재사용성** | 어려움 | 쉬움 (여러 LoRA 저장) |
| **적용 분야** | 매우 복잡한 작업 | 대부분의 실무 작업 |

### 언제 무엇을 선택할까?

**Full Fine-tuning을 선택하는 경우**
- 매우 높은 성능이 필요한 경우
- 복잡한 다단계 추론이 필요한 경우
- 예산과 시간이 충분한 경우

**LoRA를 선택하는 경우**
- 대부분의 실무 작업
- 비용 효율이 중요한 경우
- 빠른 프로토타이핑이 필요한 경우
- 여러 작업을 번갈아 사용해야 하는 경우

## 실무 적용 사례

### 1. 법률 문서 분석 모델

**목표**: 법률 용어와 판례를 정확히 이해하는 모델

**데이터 준비**
```
질문: "계약 해지 사유는 무엇인가요?"
답변: "계약 해지는 다음 사유로 가능합니다: 1) 상대방의 
      채무불이행, 2) 계약 위반, 3) 상호 합의..."
```

**LoRA 적용**
- 학습 데이터: 5,000개 법률 Q&A 쌍
- 비용: $50
- 시간: 4시간
- 결과: 법률 용어 정확도 85% → 95%

### 2. 의료 진단 지원 모델

**목표**: 의학 용어와 증상을 정확히 이해하는 모델

**데이터 준비**
```
입력: "환자 증상: 발열, 두통, 인후통"
출력: "가능한 진단: 1) 감기 (가능성 60%), 2) 독감 (가능성 30%)..."
```

**LoRA 적용**
- 학습 데이터: 10,000개 의료 케이스
- 비용: $80
- 시간: 6시간
- 결과: 의학 용어 정확도 80% → 92%

### 3. 회사 내부 챗봇

**목표**: 회사 정책과 절차를 정확히 안내하는 모델

**데이터 준비**
```
질문: "연차 신청은 어떻게 하나요?"
답변: "1. 인사시스템 로그인 → 2. 연차 신청 메뉴 선택 → 
      3. 날짜 선택 → 4. 사유 입력 → 5. 제출"
```

**LoRA 적용**
- 학습 데이터: 3,000개 회사 정책 Q&A
- 비용: $30
- 시간: 2시간
- 결과: 회사 정책 정확도 70% → 90%

### 4. 코드 리뷰 자동화

**목표**: 회사 코딩 스타일 가이드를 따르는 리뷰 생성

**데이터 준비**
```
코드: "function getUser() { return users[0]; }"
리뷰: "에러 처리가 없습니다. users 배열이 비어있을 경우 
      undefined를 반환할 수 있습니다."
```

**LoRA 적용**
- 학습 데이터: 8,000개 코드-리뷰 쌍
- 비용: $60
- 시간: 5시간
- 결과: 코딩 스타일 준수율 75% → 88%

## 실무 활용 가이드

### LoRA Fine-tuning 단계별 가이드

#### 1단계: 데이터 준비

**데이터 형식**
```json
[
  {
    "instruction": "질문 또는 지시",
    "input": "추가 컨텍스트 (선택)",
    "output": "원하는 답변"
  }
]
```

**예시**
```json
[
  {
    "instruction": "이 법률 조문을 해석해줘",
    "input": "계약은 당사자 간의 합의로 성립한다",
    "output": "계약은 양 당사자가 서로 의사를 일치시키면 
               성립합니다. 서면이나 특별한 형식이 필수는 
               아닙니다."
  }
]
```

**데이터 양**
- 최소: 500-1,000개
- 권장: 3,000-10,000개
- 이상: 10,000개 이상

#### 2단계: 모델 선택

**권장 모델**
- Llama 2 7B (오픈소스, 무료)
- Mistral 7B (오픈소스, 무료)
- GPT-3.5 (OpenAI, 유료)

**선택 기준**
- 오픈소스 선호: Llama 2, Mistral
- 높은 성능 필요: GPT-3.5
- 비용 고려: 오픈소스 모델

#### 3단계: 학습 도구 선택

**인기 도구**
- Hugging Face PEFT (추천)
- LoRAX
- Axolotl

**Hugging Face PEFT 예시**
```python
from peft import LoraConfig, get_peft_model

# LoRA 설정
lora_config = LoraConfig(
    r=8,  # LoRA rank
    lora_alpha=16,
    target_modules=["q_proj", "v_proj"],
    lora_dropout=0.1,
)

# 모델에 LoRA 적용
model = get_peft_model(base_model, lora_config)
```

#### 4단계: 학습 실행

**학습 파라미터**
- Epochs: 3-5
- Learning rate: 1e-4 ~ 5e-4
- Batch size: 4-8
- LoRA rank: 8-16

**예상 시간**
- 1,000개 데이터: 30분-1시간
- 10,000개 데이터: 2-6시간

#### 5단계: 평가 및 개선

**평가 방법**
- 테스트 데이터셋으로 정확도 측정
- 실제 사용자 피드백 수집
- A/B 테스트

**개선 방법**
- 데이터 품질 개선
- LoRA rank 증가 (r=8 → r=16)
- 학습 데이터 추가

## Fine-tuning vs RAG 비교

| 구분 | Fine-tuning | RAG |
|------|-------------|-----|
| **정보 업데이트** | 재학습 필요 | 문서 추가만 하면 됨 |
| **비용** | $30-100 (LoRA) | $0-10 (검색 비용) |
| **속도** | 학습 시간 필요 | 즉시 적용 |
| **정확도** | 패턴 학습 가능 | 검색 품질 의존 |
| **용도** | 스타일, 형식 학습 | 사실 정보 제공 |
| **적용 시기** | 초기 구축 시 | 지속적 업데이트 |

### 함께 사용하기

Fine-tuning과 RAG를 함께 사용하면 더 좋은 결과를 얻을 수 있다.

**전략**
1. Fine-tuning: 스타일, 형식, 기본 패턴 학습
2. RAG: 최신 정보, 구체적 사실 제공

**예시: 회사 챗봇**
- Fine-tuning: 회사 톤앤매너, 답변 형식 학습
- RAG: 최신 정책 문서, 공지사항 제공

## 주의사항과 한계

### 1. 데이터 품질의 중요성

나쁜 데이터로 학습하면 나쁜 모델이 만들어진다.

**나쁜 예시**
- 오류가 있는 데이터
- 일관성 없는 형식
- 불충분한 데이터

**좋은 예시**
- 정확하고 검증된 데이터
- 일관된 형식
- 충분한 양의 데이터

### 2. 과적합 (Overfitting)

학습 데이터에만 과도하게 맞춰질 수 있다.

**증상**
- 학습 데이터: 95% 정확도
- 테스트 데이터: 70% 정확도

**해결**
- 학습 데이터를 train/validation/test로 분리
- Early stopping 사용
- 데이터 증강 (Data Augmentation)

### 3. 도메인 외 데이터 처리

학습한 도메인 외 질문에는 성능이 떨어질 수 있다.

**해결**
- 일반 지식 데이터도 일부 포함
- RAG와 함께 사용
- 명확한 범위 설정

## FAQ

**Q: Fine-tuning과 LoRA의 차이는 무엇인가요?**  
A: Fine-tuning은 모델의 모든 파라미터를 업데이트하지만, LoRA는 작은 행렬만 추가해 학습합니다. LoRA는 비용이 1/100 수준으로 저렴하고 학습 시간도 훨씬 짧습니다. 성능은 Full Fine-tuning보다 약간 낮을 수 있지만, 대부분의 실무 작업에서는 충분합니다.

**Q: LoRA는 언제 사용해야 하나요?**  
A: 특정 도메인에 특화된 모델이 필요하거나, 특정 출력 형식이나 스타일을 학습시켜야 할 때 사용합니다. 법률, 의학, 회사 내부 챗봇 등에 적합합니다. 비용 효율이 중요하고 빠른 프로토타이핑이 필요한 경우 LoRA를 추천합니다.

**Q: Fine-tuning에는 얼마나 많은 데이터가 필요하나요?**  
A: 최소 500-1,000개, 권장 3,000-10,000개입니다. 데이터 품질이 중요하므로, 적은 양이라도 정확하고 일관된 데이터를 사용하는 것이 좋습니다. 복잡한 작업일수록 더 많은 데이터가 필요합니다.

**Q: Fine-tuning과 RAG 중 어떤 것을 선택해야 하나요?**  
A: 스타일, 형식, 기본 패턴을 학습해야 하면 Fine-tuning을, 최신 정보나 구체적 사실을 제공해야 하면 RAG를 사용하세요. 두 가지를 함께 사용하면 더 좋은 결과를 얻을 수 있습니다. Fine-tuning으로 기본 스타일을 학습하고, RAG로 최신 정보를 제공하는 전략이 효과적입니다.

**Q: LoRA 학습 비용은 얼마나 드나요?**  
A: 데이터 1,000개 기준 약 $30-50, 10,000개 기준 약 $50-100입니다. GPU 시간과 모델 크기에 따라 달라지지만, Full Fine-tuning의 1/100 수준입니다. 오픈소스 모델을 사용하면 더 저렴하게 학습할 수 있습니다.

**Q: Fine-tuning한 모델을 어떻게 배포하나요?**  
A: LoRA의 경우 작은 파일(MB 단위)만 추가로 배포하면 됩니다. 원본 모델과 LoRA 가중치를 함께 로드해 사용합니다. Hugging Face나 자체 서버에 배포할 수 있으며, API 형태로 제공하는 것이 일반적입니다.

