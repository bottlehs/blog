---
templateKey: blog-post
title: AI가 스스로 행동한다? LLM과 AI Agent의 충격적인 차이
date: 2025-11-01T14:00:00.000Z
category: ai
description:
  AI Agent의 정의와 작동 원리를 비유로 설명합니다.
  단순 LLM과 Agent의 차이, Agent가 어떻게 목표를 달성하는지 알아봅니다.
tags:
  - AI Agent
  - 에이전트
  - Agent
  - AI
  - 인공지능
  - 자율 에이전트
  - LLM
---

채팅GPT를 사용해본 사람이라면 한 번쯤 이렇게 생각했을 것이다. "이 AI는 왜 지식만 있고 행동은 못할까?" 채팅GPT는 질문에 답변만 할 뿐, 실제로 무엇을 하지는 못한다. 하지만 AI Agent는 다르다. 목표를 주면 스스로 계획하고 실행한다. 이 글은 LLM과 AI Agent의 차이를 명확히 보여주고, AI Agent가 어떻게 스스로 행동하는지 설명한다.

## LLM과 Agent: 질문에 답할 뿐이냐, 행동까지 할 수 있냐?

AI의 세계에는 두 가지 유형이 있다. 하나는 **LLM(Large Language Model)**이고, 다른 하나는 **AI Agent(에이전트)**다. 둘 다 비슷해 보이지만 작동 방식은 완전히 다르다.

### LLM: 대답만 하는 AI

채팅GPT를 떠올려보자. 질문을 하면 답변을 한다. "파리 프랑스의 수도는?"이면 "네, 파리는 프랑스의 수도입니다"라고 답한다. 하지만 여기서 끝이다. 더 이상 하는 일이 없다.

LLM의 특성:
- 질문을 받는다
- 답변을 생성한다
- 행동은 하지 않는다

### AI Agent: 스스로 행동하는 AI

AI Agent는 질문에 답하는 것이 아니라 **목표를 달성하기 위해 행동**한다. 

예를 들어 "서울에서 부산으로 여행 일정을 세워줘"라고 요청하면, AI Agent는 다음과 같이 행동한다:
1. KTX 시간표 검색
2. 좋은 호텔 검색
3. 주변 맛집 조사
4. 예약 사이트 정보 검색
5. 일정표 생성
6. 구글 캘린더에 일정 추가 제안
7. 최종 보고서 제공

이 모든 과정을 스스로 진행한다.

## Agent란 무엇인가?

Agent(에이전트)는 **특정 목표를 달성하기 위해 환경과 상호작용하며 자율적으로 행동하는 프로그램**이다. 

비유하자면, Agent는 자율적으로 일하는 직원이다. 상사(사용자)가 목표를 제시하면, 직원은 그 목표를 달성하기 위해 필요한 정보를 찾고, 계획을 세우고, 실행하고, 결과를 확인한다. 실패하면 다른 방법을 시도한다.

### Agent의 4가지 핵심 요소: PTAO 사이클

Agent는 네 가지 요소가 순환하며 작동한다. 이를 PTAO 사이클(Perceive-Think-Act-Observe)이라고 부른다.

#### 1. Perceive (인식): 상황 파악하기

Perceive 단계에서 Agent는 다음을 인식한다:
- 사용자의 요청: "일기예보를 보고 내일 외출할 옷차림을 추천해줘"
- 환경 정보: 현재 시간, 사용자 위치 등
- 이전 결과: 전에 시도했던 행동의 성공/실패

예를 들어 날씨 관련 질문이 들어오면, Agent는 먼저 날씨 정보를 얻어야 한다는 것을 인식한다.

#### 2. Think (사고/계획): 어떻게 할지 결정하기

Think 단계에서는 다음을 결정한다:
- 목표 달성을 위해 무엇이 필요한가?
- 어떤 순서로 행동할 것인가?
- 어떤 도구를 사용할 것인가?

LLM을 사용해 계획을 세운다. 예를 들어:
```
목표: 내일 날씨에 맞는 옷차림 추천
필요한 정보:
1. 사용자 위치
2. 내일 날씨 정보
3. 현재 시즌과 옷차림 패턴

계획:
1. 날씨 API 호출
2. 위치 기반 온도 확인
3. 옷차림 추천 생성
4. 사용자에게 제시
```

#### 3. Act (행동): 실행하기

Act 단계에서는 실제로 행동한다:
- API 호출: 날씨 정보 받아오기
- 데이터베이스 검색: 상품 정보 찾기
- 코드 실행: 파일 처리, 계산 등
- 외부 도구 사용: 검색 엔진, 캘린더, 이메일 등

Agent는 외부 세계와 연결되어 있어야 한다. 단순히 생각만 하는 LLM과 달리, Agent는 실제로 무엇인가를 수행한다.

#### 4. Observe (관찰): 결과 확인하기

Observe 단계에서는 행동의 결과를 확인한다:
- 성공했는가? 실패했는가?
- 결과가 목표에 부합하는가?
- 다음 행동이 필요한가?

만약 날씨 API 호출이 실패했다면, 다른 API를 시도하거나 사용자에게 수동으로 입력을 요청할 수 있다.

이 네 단계를 반복하면서 Agent는 목표를 달성한다.

## Agent 동작 시나리오: 여행 일정 세우기

전체 과정을 여행 일정 Agent 예시로 보자.

### 목표
"3일 후 서울에서 부산으로 1박 2일 여행 계획을 세워줘"

### 실행 과정

#### 라운드 1
**Perceive**: 사용자가 한국의 두 도시 간 여행 계획을 원함
**Think**: 
- 목적지 확인: 서울 → 부산
- 기간: 1박 2일
- 필요 정보: 교통편, 숙소, 관광지, 맛집
- 계획: KTX 시간표 → 숙소 → 관광지 순서로 진행

**Act**: KTX 시간표 검색 API 호출
**Observe**: KTX 출발 시간 9:00, 11:00, 13:00 등 확인

#### 라운드 2
**Perceive**: KTX 시간표 확인됨, 다음은 숙소
**Think**: 부산 해운대 근처 해변 호텔이 좋을 것 같음
**Act**: 숙소 검색 API 호출, 평점 높은 호텔 조회
**Observe**: A호텔(평점 4.5, 해운대 근처) 확인

#### 라운드 3
**Perceive**: 숙소 확인, 이제 관광지
**Think**: 부산 명소 정보 필요
**Act**: 부산 관광지 검색 API 호출
**Observe**: 해운대, 광안리, 감천문화마을 등 목록 확인

#### 라운드 4
**Perceive**: 기본 정보 모두 확인됨
**Think**: 일정표 작성하고 사용자에게 제시
**Act**: 
- 일정표 생성
- 구글 캘린더에 추가할 수 있는 형식으로 제공
- 예약 링크 포함
**Observe**: 최종 보고서 완성, 사용자에게 제시

이 과정에서 Agent는 스스로 다음 단계를 결정하고, 필요한 정보를 찾고, 결과를 종합한다.

## LLM vs Agent: 자세한 비교

| 구분 | LLM | AI Agent |
|------|-----|----------|
| **응답 방식** | 질문에 대해 답변만 생성 | 목표를 위해 스스로 행동 |
| **도구 사용** | 불가능 | 가능 (검색, API, DB 등) |
| **목표 달성** | 정보 제공 수준 | 실제 작업 완수 |
| **학습 능력** | 정적 (변하지 않음) | 피드백으로 개선 가능 |
| **대화 흐름** | 순차적 Q&A | 목표 중심 순환 |
| **환경과의 상호작용** | 없음 | 있음 (API, 시스템 호출) |
| **자율성** | 없음 (사용자가 계속 질문) | 있음 (스스로 판단) |
| **비용** | 낮음 | 높음 (많은 API 호출) |
| **속도** | 빠름 | 느림 (여러 단계 필요) |

### 실제 예시로 차이점 이해하기

**시나리오: "서울에 내일 비 올까?"**

**LLM의 경우:**
```
사용자: 서울에 내일 비 올까?
LLM: 죄송합니다, 실시간 날씨 정보는 제공할 수 없습니다. 
     학습된 데이터만 기반으로 답변하므로 최신 날씨는 알 수 없습니다.
```

**Agent의 경우:**
```
사용자: 서울에 내일 비 올까?
Agent: [날씨 API 호출] 네, 내일 서울에는 오후 2시부터 비가 올 예정입니다.
       우산을 준비하시기 바랍니다.
```

LLM은 학습 데이터에 있는 정보만 제공하지만, Agent는 실시간으로 날씨 정보를 가져올 수 있다.

## Agent의 다양한 유형

Agent는 목적과 구조에 따라 여러 유형으로 나뉜다.

### 1. ReAct Agent: 추론과 행동의 반복

ReAct(Reasoning + Acting)는 가장 일반적인 Agent 패턴이다. 

**특징:**
- 한 번에 하나의 행동만 수행
- 행동 → 결과 확인 → 다음 행동 결정 반복
- 각 단계에서 명시적으로 추론 과정을 보여줌

**장점:** 투명하고 예측 가능
**단점:** 복잡한 작업에서는 시간이 오래 걸림

**예시:**
```
생각: 사용자가 프랑스어 문서 번역이 필요함
행동: 번역 API 호출
결과: 번역 완료, 문서 수신
생각: 번역이 완료되었으니 사용자에게 전달
행동: 결과 제시
```

### 2. Tool-using Agent: 도구를 활용하는 전문가

Tool-using Agent는 다양한 도구를 잘 다룬다.

**특징:**
- 검색, 계산기, API, 데이터베이스 등을 도구로 사용
- 각 도구의 장단점을 알고 적절하게 선택
- 복잡한 작업을 여러 도구 조합으로 해결

**예시 도구들:**
- 검색 도구: 최신 정보 검색
- 계산 도구: 수학 계산
- 파일 도구: 파일 읽기/쓰기
- API 도구: 외부 서비스 연결
- 데이터베이스: 구조화된 데이터 조회

**예시:**
```
작업: 회사의 2024년 매출 분석
도구 사용:
1. DB 도구: 매출 데이터 조회
2. 계산 도구: 월별/분기별 집계
3. 차트 생성 도구: 시각화
4. 리포트 도구: 최종 리포트 작성
```

### 3. Multi-Agent: 협업하는 AI 팀

Multi-Agent는 여러 Agent가 함께 일한다.

**특징:**
- 각 Agent가 다른 역할을 맡음
- 서로 협력해 복잡한 문제 해결
- 특화된 Agent 조합으로 효율성 극대화

**예시 팀 구성:**
- 기획자 Agent: 전체 계획 수립
- 개발자 Agent: 코드 작성
- 검토자 Agent: 코드 품질 체크
- 테스터 Agent: 테스트 및 버그 찾기
- 매니저 Agent: 전체 조율

**예시 시나리오:**
```
작업: 간단한 웹앱 만들기

기획자 Agent: "사용자 인증 기능이 필요합니다"
개발자 Agent: "로그인, 회원가입 코드 작성"
검토자 Agent: "보안 취약점 있음, 수정 필요"
테스터 Agent: "테스트 통과"
매니저 Agent: "모든 단계 완료 확인"
```

### 4. AutoGPT: 장기 목표를 추구하는 자율 Agent

AutoGPT는 장기적인 목표를 스스로 달성한다.

**특징:**
- 사용자가 한 번 목표만 주면 끝까지 진행
- 중간 목표를 스스로 설정
- 계속 진행하다 막히면 새로운 접근 시도

**예시:**
```
목표: 부동산 투자 계획 수립

AutoGPT의 자율 실행:
1. 현재 부동산 시장 조사
2. 투자자 예산 확인
3. 다양한 투자 옵션 비교 (아파트, 상가, 토지)
4. 리스크 분석
5. 추천 투자안 제시
6. 추가 질문에 대한 응답 준비
```

이미 시작한 목표를 단계적으로 진행한다.

## 일상 속 Agent 활용 사례

Agent는 이미 우리 삶 곳곳에서 활동하고 있다.

### 1. 고객 상담 챗봇

전자상거래 사이트의 챗봇은 단순 대답이 아니라 실제로 행동한다:
- 주문 조회 API 호출
- 환불 신청 처리
- 배송 상태 실시간 확인
- 상품 추천 알고리즘 실행

사용자는 "주문 12345 상태 확인해줘"라고만 말하면, Agent가 배송 시스템에 접속해 실제 정보를 가져온다.

### 2. 일정 관리 비서

AI 비서는 이메일을 읽고 일정을 추가한다:
- 이메일에서 회의 정보 추출
- 캘린더 API로 일정 추가
- 참석자에게 확정 메일 전송
- 회의실 예약까지 완료

### 3. 코드 개발 Agent

GitHub Copilot 같은 Agent는:
- 코드를 분석해 버그 찾기
- 테스트 코드 자동 생성
- 문서 작성
- 리팩토링 제안

개발자가 "API 엔드포인트 추가해줘"라고 하면, Agent가 DB 설정부터 API 코드까지 작성한다.

### 4. 자율주행 자동차

자율주행 자동차는 완전한 Agent다:
- 카메라와 센서로 환경 인식
- 주변 상황 분석
- 최적 경로 계획
- 실제 제어 수행
- 결과 모니터링 및 재계획

### 5. 스마트홈 IoT Agent

스마트홈 Agent는:
- 집 내 온도/습도/조명 상태 감지
- 사용자 패턴 학습
- 자동 온도 조절
- 에너지 절약 최적화

## Agent의 한계와 도전 과제

Agent는 강력하지만 완벽하지 않다. 여러 한계가 있다.

### 1. 높은 비용

Agent는 많은 LLM 호출과 API 사용으로 비용이 크다:
- LLM 호출: 한 작업당 수십~수백 번
- 외부 API: 각 단계마다 호출
- 처리 시간: 긴 실행으로 인프라 비용

**예시:** 여행 일정 하나 만드는 데 수달러 소요

### 2. 불확실성과 실수

Agent의 행동 결과는 보장되지 않는다:
- API 실패 가능
- 잘못된 판단
- 무한 루프 진입
- 예상치 못한 부작용

따라서 중요한 작업은 사람이 검토해야 한다.

### 3. 느린 응답 속도

여러 단계를 거쳐야 해 느리다:
- 각 행동마다 대기
- 순차 처리로 병목
- 복잡도 증가 시 급격히 느려짐

실시간 요청에는 부적합할 수 있다.

### 4. 복잡도 관리

복잡한 Agent는 디버깅이 어렵다:
- 어느 단계에서 실패했는지 추적 어려움
- 예측 불가한 동작
- 전체 플로우 최적화 곤란

## Agent의 미래: 더 똑똑해지는 AI

### 1. Long-Context Agent

맥락 길이 한계 극복:
- 긴 문서 처리
- 장기 기억 유지
- 복잡한 작업 일관성 유지

**전망:** 에이전트가 한 달치 프로젝트를 기억하며 진행

### 2. 메모리 강화 Agent

외부 메모리 도입:
- 과거 경험 학습
- 성공 패턴 재사용
- 실패 방지

**전망:** 실수 없이 안정적으로 작동

### 3. 협력 Agent 네트워크

에이전트 간 협력:
- 분산 처리
- 전문성 공유
- 효율적 문제 해결

**전망:** 에이전트 소셜 네트워크 실현

### 4. 실시간 학습 Agent

지속적 스킬 향상:
- 수행 도중 학습
- 패턴 발견
- 최적화

**전망:** 사용자와 함께 발전

## 결론: LLM은 대답하고, Agent는 행동한다

LLM은 질문에 답한다. Agent는 목표를 받아 스스로 행동한다. PTAO 사이클(인식·사고·행동·관찰)이 핵심이다.

Agent는 비용·속도·불확실성 한계가 있다. 실시간, 저비용, 정확·안정이 필요하다면 LLM이 더 적합하다.

앞으로 에이전트는 더 안정적이고 실용적이 될 것이다. 남은 과제는 비용·속도·안정성 개선이다.

이미 많은 일상 영역에 적용되고 있다. Agent의 작동 원리를 이해하고 한계를 알면, 활용과 협업이 더 나아진다.

